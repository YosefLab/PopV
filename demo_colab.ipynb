{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e0bca785",
      "metadata": {
        "id": "e0bca785"
      },
      "source": [
        "# Using Tabula Sapiens as a reference for annotating new datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e01a8a33-3e2f-4cce-b159-73a448e1d712",
      "metadata": {
        "id": "e01a8a33-3e2f-4cce-b159-73a448e1d712"
      },
      "source": [
        "This notebook allows you to annotate your data with a number of annotation methods using the Tabula Sapiens dataset as the reference. \n",
        "\n",
        "Initial setup: \n",
        "1. Make sure GPU is enabled (Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU)\n",
        "2. We also highly recommend getting Colab PRO for access to a high ram session.\n",
        "\n",
        "\n",
        "Integration Methods Provided:\n",
        "- scVI [(Lopez et al. 2018)](https://www.nature.com/articles/s41592-018-0229-2)\n",
        "- bbKNN [(Polański et al. 2020)](https://academic.oup.com/bioinformatics/article/36/3/964/5545955)\n",
        "- Scanorama [(He et al. 2019)](https://www.nature.com/articles/s41587-019-0113-3)\n",
        "\n",
        "Annotation Methods:\n",
        "- KNN on integrated spaces\n",
        "- scANVI [(Xu et al. 2021)](https://www.embopress.org/doi/full/10.15252/msb.20209620)\n",
        "- onClass [(Wang et al. 2020)](https://www.biorxiv.org/content/10.1101/810234v2)\n",
        "- Celltypist [(Dominguez Conde et al. 2022)](https://www.science.org/doi/10.1126/science.abl5197)\n",
        "- SVM \n",
        "- RandomForest\n",
        "\n",
        "To use the notebook, simply connect to your Google Drive account, set the necessary arguments, select your methods, and run all the code blocks!\n",
        "\n",
        "**User action is only required in Steps 1-3.**\n",
        "\n",
        "Last edited: 6/27/2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45661f72-94d4-47b3-b941-53a2e8bab666",
      "metadata": {
        "id": "45661f72-94d4-47b3-b941-53a2e8bab666"
      },
      "source": [
        "## Step 1: Setup environment\n",
        "\n",
        "We omit the output of those lines for readability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h41Q6U5wMwyP",
      "metadata": {
        "id": "h41Q6U5wMwyP"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "clone_github_repo = False # Set to True if running outside of already exisiting Github repository.\n",
        "if clone_github_repo:\n",
        "    !git clone --quiet https://github.com/czbiohub/PopV.git"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MlQ3oQoRtd1C",
      "metadata": {
        "id": "MlQ3oQoRtd1C"
      },
      "source": [
        "# Restart the Runtime after installation (User Action Required)\n",
        "\n",
        "Runtime -> \"Restart runtime\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a6c4df4",
      "metadata": {
        "id": "1a6c4df4"
      },
      "outputs": [],
      "source": [
        "2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "935b37ea-29ee-4134-b793-fb1be48d1156",
      "metadata": {
        "id": "935b37ea-29ee-4134-b793-fb1be48d1156"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Restart the runtime before running this cell\n",
        "import popv\n",
        "import numpy as np\n",
        "import scanpy as sc\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9039153f-9c09-4486-a5b0-fec6c733bf8e",
      "metadata": {
        "id": "9039153f-9c09-4486-a5b0-fec6c733bf8e"
      },
      "source": [
        "# Step 2: Load your data (User Action Required)\n",
        "Here we provide three options to load your data:\n",
        "1. Connect to Google Drive (highly recommended)\n",
        "2. Download your data from the cloud and save into this session or on Google drive.\n",
        "3. Upload your data manually into this session (files are not persistent and will be deleted when session is closed)\n",
        "\n",
        "As an example, we use a subsampled version of the [Lung Cell Atlas](https://hlca.ds.czbiohub.org/) \\[1] for our query data.\n",
        "\n",
        "\\[1] Travaglini, K. et al. A molecular cell atlas of the human lung from single-cell RNA sequencing. *Nature* **587**, 619–625(2020)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfa9ac7b",
      "metadata": {
        "id": "cfa9ac7b"
      },
      "outputs": [],
      "source": [
        "output_folder = 'tmp_testing'\n",
        "if not os.path.exists(output_folder):\n",
        "    os.mkdir(output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lkm3ELAfV8-D",
      "metadata": {
        "id": "lkm3ELAfV8-D"
      },
      "outputs": [],
      "source": [
        "input_file ={'source': 'wget', 'path': 'tmp_testing/LCA.h5ad', 'link': 'https://www.dropbox.com/s/mrf8y7emfupo4he/LCA.h5ad?dl=1'}\n",
        "\n",
        "if input_file['source']== 'gdrive':\n",
        "  # OPTION 1: Connect to Google Drive\n",
        "  # This is the recomended method especially for large datasets\n",
        "  from google.colab import drive    \n",
        "  drive.mount('/content/drive')\n",
        "  query_adata = sc.read(input_file['path'])\n",
        "elif input_file['source'] == 'local':\n",
        "  # OPTION 2: Uploading data manually\n",
        "  # Click the folder icon on the left navigation bar, and select the upload icon\n",
        "  # Note: Manually uploaded data is automatically deleted when the colab session ends\n",
        "  # This is not recommended if your dataset is very large\n",
        "  query_adata = sc.read(input_file['path'])\n",
        "else:\n",
        "  # OPTION 3: Downloading from the cloud (Dropbox, AWS, Google Drive, etc)\n",
        "  # Google Colab supports wget, curl, and gdown commands\n",
        "  # It is recommended to download the data into Google Drive and read from there.\n",
        "  # This way your data will be persistent.\n",
        "  print('downloading')\n",
        "  try:\n",
        "    !wget -O {input_file['path']} {input_file['link']}\n",
        "    query_adata = sc.read(input_file['path'])\n",
        "  except:\n",
        "    raise Exception(f'Default download failed with wget. Use custom downloader or check provided link ' + input_file['link'])\n",
        "    \n",
        "query_adata.obs_names_make_unique()\n",
        "# query_adata = query_adata[np.random.choice(query_adata.obs_names, 1000, replace=False)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eQwL4OPPu-o7",
      "metadata": {
        "id": "eQwL4OPPu-o7"
      },
      "source": [
        "# Step 3 (User Action Required): Setting Up Annotation Parameters \n",
        "\n",
        "Here is where you set the parameters for the automated annotation.\n",
        "\n",
        "Arguments:\n",
        "- **tissue:** Tabula Sapiens tissue to annotate your data with. Available tissues: [\"Bladder\", \"Blood\", \"Bone_Marrow\", \"Kidney\", \"Large_Intestine\", \"Lung\",\"Lymph_Node\", \"Pancreas\", \"Small_Intestine\", \"Spleen\", \"Thymus\",\"Trachea\", \"Vasculature\"]\n",
        "- **save_location:** location to save results to. By default will save to a folder named `annotation_results`. It is highly recommended you provide a Google Drive folder here.\n",
        "- **query_batch_key:** key in `query_adata.obs` for batch correction. Set to None for no batch correction. \n",
        "- **algorithms:** these are the methods to run. By default, will run all methods.\n",
        "Options: [\"knn_on_scvi_pred\", \"scanvi_pred\", \"knn_on_bbknn_pred\", \"svm_pred\", \"rf_pred\", \"onclass_pred\", \"knn_on_scanorama_pred\",\n",
        "\n",
        "\n",
        "Lesser used parameters\n",
        "- **query_labels_key**: scANVI has the option to use labeled cells in the query dataset during training. To use some prelabeled cells from the query dataset, set `query_labels_key` to the corresponding key in `query_adata.obs`\n",
        "- **unknown_celltype_label**: If `query_labels_key` is not None, will treat everything not labeled `unknown_celltype_label` as a labeled cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RBolKuGDvP0Z",
      "metadata": {
        "id": "RBolKuGDvP0Z"
      },
      "outputs": [],
      "source": [
        "\"\"\" \n",
        "tissue options: \n",
        "['Bladder','Blood','Bone_Marrow','Fat',\n",
        "'Heart','Kidney','Large_Intestine','Liver',\n",
        "'Lung','Lymph_Node','Mammary','Muscle',\n",
        "'Pancreas','Prostate','Salivary Gland',\n",
        "'Skin','Small_Intestine','Spleen',\n",
        "'Thymus','Trachea','Vasculature']\n",
        "\"\"\"\n",
        "tissue = 'Lung'\n",
        "\n",
        "query_batch_key = 'donor_method'\n",
        "algorithms = None\n",
        "\n",
        "# Lesser used parameters\n",
        "query_labels_key=None\n",
        "unknown_celltype_label='unknown'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffB8B0dUceGb",
      "metadata": {
        "id": "ffB8B0dUceGb"
      },
      "source": [
        "# Step 4: Downloading Reference Data and Pretrained Models\n",
        "No more user input required! Just run all the following code blocks.\n",
        "\n",
        "**NOTE: PopV has only been evaluated with the Lung/Thymus/Lymph_Node as a reference dataset. Different tissues have different annotation quality and the Tabula sapiens community is currently actively improving the annotation quality. We strongly expect improvement of cell annotation when the updated annotation is released. Upon release the Zenodo repository will be updated.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zty7C8HAZwwr",
      "metadata": {
        "id": "Zty7C8HAZwwr"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "res = requests.get(\"https://zenodo.org/api/records/7587774\")\n",
        "tissue_download_path = {ind['key'][3:-14]:ind['links']['self'] for ind in res.json()['files']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfc3c4a5",
      "metadata": {
        "id": "cfc3c4a5"
      },
      "outputs": [],
      "source": [
        "res = requests.get(\"https://zenodo.org/api/records/7580707\")\n",
        "pretrained_models_download_path = {ind['key'][18:-10]:ind['links']['self'] for ind in res.json()['files']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d63bea8",
      "metadata": {
        "id": "3d63bea8"
      },
      "outputs": [],
      "source": [
        "refdata_url = tissue_download_path[tissue]\n",
        "output_fn = f'{output_folder}/TS_{tissue}.h5ad'\n",
        "if not os.path.exists(output_fn):\n",
        "    !wget -O $output_fn $refdata_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66e75578",
      "metadata": {
        "id": "66e75578"
      },
      "outputs": [],
      "source": [
        "model_url = pretrained_models_download_path[tissue]\n",
        "output_model_tar_fn = f'{output_folder}/pretrained_model_{tissue}.tar.gz'\n",
        "output_model_fn = f'{output_folder}/pretrained_model_{tissue}'\n",
        "if not os.path.exists(output_model_fn):\n",
        "    os.mkdir(output_model_fn)\n",
        "if not os.path.exists(output_model_fn):\n",
        "    !wget -O $output_model_tar_fn $model_url\n",
        "    !tar -xzf $output_model_tar_fn $output_model_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c268bde8",
      "metadata": {
        "id": "c268bde8"
      },
      "outputs": [],
      "source": [
        "# read in the reference dataset\n",
        "ref_adata = sc.read_h5ad(output_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a830cd8-b897-498c-b3f8-1dddff8e5aa8",
      "metadata": {
        "id": "6a830cd8-b897-498c-b3f8-1dddff8e5aa8"
      },
      "source": [
        "### Setup reference data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33ad9aa6-271f-425b-ba5b-8f554001b0c0",
      "metadata": {
        "id": "33ad9aa6-271f-425b-ba5b-8f554001b0c0"
      },
      "outputs": [],
      "source": [
        "# Following parameters are specific to Tabula Sapiens dataset and contain the annotated cell-type and the batch_key that are corrected for during model training.\n",
        "ref_labels_key='cell_ontology_class'\n",
        "ref_batch_key = 'donor_assay'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e54d258-a49b-430f-818c-d16a2cf068ed",
      "metadata": {
        "id": "4e54d258-a49b-430f-818c-d16a2cf068ed"
      },
      "outputs": [],
      "source": [
        "min_celltype_size = np.min(ref_adata.obs.groupby(ref_labels_key).size())\n",
        "n_samples_per_label = np.max((min_celltype_size, 500))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de507788-dfc3-4b54-979b-f0472ac014f5",
      "metadata": {
        "id": "de507788-dfc3-4b54-979b-f0472ac014f5"
      },
      "source": [
        "### Preprocess query with ref dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db50776c-e9d2-4198-8b19-b0cdebd6b167",
      "metadata": {
        "id": "db50776c-e9d2-4198-8b19-b0cdebd6b167"
      },
      "outputs": [],
      "source": [
        "from popv.preprocessing import Process_Query\n",
        "\n",
        "adata = Process_Query(\n",
        "        query_adata,\n",
        "        ref_adata,\n",
        "        query_labels_key=query_labels_key,\n",
        "        query_batch_key=query_batch_key,\n",
        "        ref_labels_key=ref_labels_key,\n",
        "        ref_batch_key=ref_batch_key,\n",
        "        unknown_celltype_label=unknown_celltype_label,\n",
        "        save_path_trained_models=output_model_fn,\n",
        "        prediction_mode='inference', # 'fast' mode gives fast results (does not include BBKNN and Scanorama and makes more inaccurate errors)\n",
        "        n_samples_per_label=n_samples_per_label,\n",
        "        use_gpu=True,\n",
        "        compute_embedding=True,\n",
        "        hvg=None\n",
        "    ).adata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a66f98d3",
      "metadata": {
        "id": "a66f98d3"
      },
      "outputs": [],
      "source": [
        "adata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e6b602d-8e13-4e1d-b31e-632a0c4a2284",
      "metadata": {
        "collapsed": true,
        "id": "1e6b602d-8e13-4e1d-b31e-632a0c4a2284"
      },
      "outputs": [],
      "source": [
        "from popv.annotation import annotate_data\n",
        "annotate_data(adata, save_path=f'{output_folder}/popv_output')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57be6575",
      "metadata": {
        "id": "57be6575"
      },
      "outputs": [],
      "source": [
        "# Optional: save the full anndata will all objects\n",
        "# adata.write(f'{output_folder}/query_and_reference_popv.h5ad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31479a95",
      "metadata": {
        "id": "31479a95"
      },
      "outputs": [],
      "source": [
        "adata.obsm['X_umap'] = adata.obsm['X_scanvi_umap_popv']\n",
        "\n",
        "sc.pl.umap(adata,\n",
        "           color=['popv_prediction', 'popv_celltypist_prediction', 'popv_scanvi_prediction', 'popv_prediction_score', 'cell_ontology_type'], ncols=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be872076-2fb5-4b41-bc00-70dc93f9d647",
      "metadata": {
        "id": "be872076-2fb5-4b41-bc00-70dc93f9d647"
      },
      "source": [
        "# Step 6: Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8632ea25-66a2-4845-938b-2559aede3402",
      "metadata": {
        "id": "8632ea25-66a2-4845-938b-2559aede3402"
      },
      "outputs": [],
      "source": [
        "popv.visualization.make_agreement_plots(adata, prediction_keys=adata.uns['prediction_keys'] + ['onclass_seen'], save_folder=output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Syp_KoY_qRDy",
      "metadata": {
        "id": "Syp_KoY_qRDy"
      },
      "outputs": [],
      "source": [
        "popv.visualization.prediction_score_bar_plot(adata, popv_prediction_score=\"popv_prediction_score\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J12TFk3cqYfR",
      "metadata": {
        "id": "J12TFk3cqYfR"
      },
      "outputs": [],
      "source": [
        "popv.visualization.agreement_score_bar_plot(adata)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3AAB19Nvq2CF",
      "metadata": {
        "id": "3AAB19Nvq2CF"
      },
      "source": [
        "### Cell type proportion plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QICg6X5FrmfY",
      "metadata": {
        "id": "QICg6X5FrmfY"
      },
      "outputs": [],
      "source": [
        "popv.visualization.celltype_ratio_bar_plot(adata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e62b67e",
      "metadata": {
        "id": "4e62b67e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "PopV",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "ae9b7835f8811f2422472b7a077be27a1569af3ecea40a1678b81babec34df9c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}